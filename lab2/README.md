# Лабораторная работа 2: Плохие и хорошие практики в Docker

### 1. Плохие практики в `bad.Dockerfile` и их исправление в `good.Dockerfile`

1.  **Использование тега `latest`**
    *   **Почему это плохо:** Тег `latest` всегда указывает на самую новую версию образа. Если сегодня собрать рабочий контейнер, а завтра кто-то обновит базовый образ, то следующая сборка этого контейнера может использовать уже другую, несовместимую версию и перестать работать. Нельзя быть уверенным, что через месяц или год получится собрать точно такой же контейнер.
    *   **Исправление:** В `good.Dockerfile` изпользуется конкретный тег `python:3.11-slim-bullseye`, чтобы все сборки гарантировано использовали одну и ту же среду.
    *   **Результат:** Сборки стали стабильными и воспроизводимыми.

2.  **Неоптимальное использование инструкций `RUN` и `COPY`**
    *   **Почему это плохо:** Каждая отдельная команда `RUN` увеличивает итоговый размер контейнера, и чем больше таких команд, тем "тяжелее" образ. Команда `COPY . /app` копирует все файлы проекта сразу, и если потом изменить даже один файл, Docker придется заново устанавливать все зависимости, потому что кэш для этого этапа сборки будет сброшен, а это очень медленно.
    *   **Исправление:** В `good.Dockerfile` сначала копируется только `requirements.txt`, и зависимости устанавливаются одной командой `RUN`, а остальной код копируется отдельно. Кэш pip очищается в той же команде.
    *   **Результат:** Размер образа уменьшен, сборки стали быстрее, так как слой с зависимостями пересобирается только при изменении `requirements.txt`, а не при любом изменении кода.

3.  **Хранение секретов в Dockerfile**
    *   **Почему это плохо:** Если вы запишете пароль или секретный ключ в Dockerfile через команду `ENV`, то этот секрет навсегда останется внутри собранного образа. Любой, кто получит образ, сможет посмотреть все переменные и украсть секретные данные.
    *   **Исправление:** Секретные коды полностью удалены из `good.Dockerfile`. Они должны передаваться в контейнер во время выполнения, например, с помощью `docker run --env-file .env` или через оркестраторы (Kubernetes Secrets, Docker Swarm secrets).
    *   **Результат:** Повышение безопасности, секретные данные не попадают в финальный образ.

### Две плохие практики по работе с контейнерами (не по Dockerfile)

1.  **Запуск контейнера в интерактивном режиме или без демонизации**
    *   **Проблема:** Запуск контейнера командой `docker run -it my_app` привязывает его к текущей сессии терминала, и если закрыть терминал или нажать `Ctrl+C`, то контейнер умрет.
    *   **Решение:** Нужно использовать флаг `-d` (detach) для запуска контейнеров в качестве демонов: `docker run -d -p 5000:5000 my_app`. ТОгда контейнер продолжить работать фоном, даже если закрыт терминал.
2.  **Использование флага `--privileged` без необходимости**
    *   **Проблема:** Запуск контейнера с `--privileged` дает ему практически полный доступ к компьютеру. А это значит, что на практике контейнер может удалять или читать любые файлы, устанавливать вирусы на компьютер отслеживать все, что делает пользователь, то есть появляется огромная угроза безопасности и конфиденциальности.
    *   **Решение:** Избегайте `--privileged`. Если контейнеру нужны специфические права, используйте более точные флаги, такие как `--cap-add` или `--device`, чтобы предоставить только необходимые минимальные привилегии.


### 2. Проверка работы контейнеров
1. Собираем образы:
```
cd Cloud_technologies_and_services/lab2
docker build -t my-bad-app -f bad.Dockerfile .
docker build -t my-good-app -f good.Dockerfile .
```
   <img width="863" height="335" alt="image" src="https://github.com/user-attachments/assets/2c31f710-2d63-426e-b990-f06642e04100" />
   <img width="853" height="459" alt="image" src="https://github.com/user-attachments/assets/7a8e7fdc-c65d-45b3-94b8-53ca930ac7f7" />
   
2. Запускаем "плохой" контейнер и проверяем его:
```
docker run -d -p 5000:5000 --name bad-container localhost/my-bad-app
curl http://localhost:5000
docker stop bad-container
```
<img width="853" height="262" alt="image" src="https://github.com/user-attachments/assets/21cf5cdc-b58e-49a0-b899-9be86ce2963c" />
<img width="852" height="103" alt="image" src="https://github.com/user-attachments/assets/c520651b-aca6-4127-8a00-0f550a4b6a4e" />

3. Запускаем "хороший" контейнер и передаем секрет через переменную окружения:
```
docker run -d -p 5001:5000 -e SECRET_KEY="secret_from_runtime" --name good-container localhost/my-good-app
curl http://localhost:5001
docker stop good-container
```
<img width="857" height="178" alt="image" src="https://github.com/user-attachments/assets/fd9c27a8-f6b9-491f-a1d6-033b89221f56" />

4. Смотрим размеры образов:
```
docker images
```
<img width="719" height="217" alt="image" src="https://github.com/user-attachments/assets/419b7f28-7704-46ab-bbb5-1cce5beca194" />

### Вывод
В ходе лаборатрной работы продемонстрирована значительная разница между подходами к контейнеризации:
**Результаты сравнения:**
- "Хороший" образ (149 MB) в 4 раза меньше "плохого" (603 MB)
- Секреты в "хорошем" контейнере передаются безопасно во время выполнения
- Использование конкретных тегов обеспечивает воспроизводимость сборок
- Оптимизация слоев Dockerfile ускоряет процесс сборки

**Итоги:**
Следование best practices напрямую влияет на безопасность, производительность и надежность контейнеров:
- "Плохие" практики приводят к избыточному размеру образов и уязвимостям безопасности
- Правильная работа с контейнерами не менее важна, чем качество Dockerfile
